{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d98e2db-8519-4cd8-9f75-9e65331585a1",
   "metadata": {},
   "source": [
    "### Autor: Johnny Rubio Pecasso\n",
    "### Fecha: 17/sep/2024\n",
    "### Introduccion a la ciencia de datos\n",
    "### Notebook ICD-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bea34-06dd-4b57-90da-dce66eeedabf",
   "metadata": {},
   "source": [
    "Install libraries via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582ef0ff-9295-4337-89ee-764fe81c0f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2415549043.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install spacy\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pip install spacy\n",
    "#pip install nltk\n",
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a1956-9666-48c5-98a5-2cbb514c22ef",
   "metadata": {},
   "source": [
    "Importing necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce4c060-b967-4856-b7cf-b6ea32740ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspc\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy as spc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d0bc4-caab-43b2-b791-7a903f2a67f6",
   "metadata": {},
   "source": [
    "## Datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f38d8f-f3e8-4bae-8afe-b74fd140ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\n"
     ]
    }
   ],
   "source": [
    "oracion = \"@Mar18blink Estoy buscando un producto genial por menos de 50. He encontrado muchos en https://t.co/FI1ShlDozc. ¿Qué opinas? Quiero comprarlo ya!!!\"\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace6213-b9e5-4dde-80f8-cffede8fc3b7",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72533121-a276-4248-9cd1-71bfdc4ce66f",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afad44f-9233-4584-9e43-5cad07ef213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n"
     ]
    }
   ],
   "source": [
    "oracion = oracion.lower()\n",
    "oracion = re.sub(r\"@\\S+\", \"\", oracion)  # Eliminar menciones a usuarios\n",
    "oracion = re.sub(\"http[s]?\\://\\S+\", \"\", oracion)  # Eliminar enlaces\n",
    "oracion = re.sub(r\"#\\S+\", \"\", oracion)  # Eliminar hashtags\n",
    "oracion = re.sub(r\"[0-9]\", \"\", oracion)  # Eliminar números\n",
    "oracion = re.sub(r\"(\\(.*\\))|(\\[.*\\])\", \"\", oracion)  # Eliminar paréntesis y corchetes\n",
    "oracion = re.sub(r\"\\n\", \"\", oracion)  # Eliminar caracteres de nueva línea\n",
    "oracion = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\", oracion)  # Eliminar varios patrones\n",
    "oracion = re.sub(r\"(\\.)|(,)\", \"\", oracion)  # Eliminar puntos y comas\n",
    "oracion = re.sub(r\"[¡!]\", \"\", oracion)  # Eliminar signos de admiración \n",
    "oracion = re.sub(r\"[¿?]\", \"\", oracion)  # Eliminar signos de exclamación\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20449-7603-4d01-9866-6be0fbf0063c",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a798d9-a52d-41bf-80b6-4d36808cee15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#nltk.download('punkt')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m(oracion)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "tokens = word_tokenize(oracion)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33108d-855f-4898-a16d-82d8fd19ee4f",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9990057-f614-463c-bc59-276163f9c16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#nltk.download('stopwords')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m spanish_stopwords \u001b[38;5;241m=\u001b[39m \u001b[43mstopwords\u001b[49m\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m palabras_filtradas \u001b[38;5;241m=\u001b[39m [palabra \u001b[38;5;28;01mfor\u001b[39;00m palabra \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m palabra \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m spanish_stopwords]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(palabras_filtradas)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "palabras_filtradas = [palabra for palabra in tokens if palabra not in spanish_stopwords]\n",
    "print(palabras_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd83dce-3bb0-4258-a752-3297c1fffa55",
   "metadata": {},
   "source": [
    "### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9854623a-2f73-46ec-8f1d-8cd14e31d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo python3 -m spacy download es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a78c030-5094-48a0-aa9c-dc63ff9bfddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspc\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes_core_news_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m lema \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(palabras_filtradas))\n\u001b[0;32m      3\u001b[0m oracion_lematizada \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m lema])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spc' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spc.load(\"es_core_news_sm\")\n",
    "lema = nlp(\" \".join(palabras_filtradas))\n",
    "oracion_lematizada = \" \".join([token.lemma_ for token in lema])\n",
    "print(oracion_lematizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d08ba-3bff-4982-8a0d-53e1b16209f4",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2736fdd5-dde2-48d7-ad8d-01d1db87f66c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectorizador \u001b[38;5;241m=\u001b[39m \u001b[43mCountVectorizer\u001b[49m()\n\u001b[0;32m      2\u001b[0m vectores \u001b[38;5;241m=\u001b[39m vectorizador\u001b[38;5;241m.\u001b[39mfit_transform([oracion_lematizada])\n\u001b[0;32m      3\u001b[0m vocabulario \u001b[38;5;241m=\u001b[39m vectorizador\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizador = CountVectorizer()\n",
    "vectores = vectorizador.fit_transform([oracion_lematizada])\n",
    "vocabulario = vectorizador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c90384-68b0-460a-8cd3-82becb828de8",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71ef6ab-76b1-4e20-adbb-5dd1c25e1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración de entrada:  estoy buscando un producto genial por menos de  he encontrado muchos en  qué opinas quiero comprarlo ya\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'oracion_lematizada' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOración de entrada:\u001b[39m\u001b[38;5;124m\"\u001b[39m, oracion)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOración lematizada:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43moracion_lematizada\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectores Bag of Words:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vectores\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulario:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vocabulario)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'oracion_lematizada' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Oración de entrada:\", oracion)\n",
    "print(\"Oración lematizada:\", oracion_lematizada)\n",
    "print(\"Vectores Bag of Words:\", vectores.toarray())\n",
    "print(\"Vocabulario:\", vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b9bcd-1d1c-443b-b06a-8551bdee0af7",
   "metadata": {},
   "source": [
    "### Construir Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c552894-bc08-4397-8982-3cb8df82052d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_bw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mfrom_spmatrix(\u001b[43mvectores\u001b[49m,columns \u001b[38;5;241m=\u001b[39m vocabulario)\n\u001b[0;32m      2\u001b[0m df_bw\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectores' is not defined"
     ]
    }
   ],
   "source": [
    "df_bw = pd.DataFrame.sparse.from_spmatrix(vectores,columns = vocabulario)\n",
    "df_bw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae042ce-df3f-4b1e-8f6d-306c9c621703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
